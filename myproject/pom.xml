<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>org.rainforc</groupId>
  <artifactId>mycode</artifactId>
  <packaging>jar</packaging>
  <version>1.0-SNAPSHOT</version>
  <name>mycode</name>
  <url>http://maven.apache.org</url>
  <properties>
    <!-- Change the nd4j.backend property to nd4j-cuda-7.5-platform or nd4j-cuda-8.0-platform to use CUDA GPUs -->
    <nd4j.backend>nd4j-native-platform</nd4j.backend>
    <!-- <nd4j.backend>nd4j-cuda-8.0-platform</nd4j.backend> -->
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <shadedClassifier>bin</shadedClassifier>
    <java.version>1.8</java.version>
    <nd4j.version>0.9.1</nd4j.version>
    <dl4j.version>0.9.1</dl4j.version>
    <datavec.version>0.9.1</datavec.version>
    <arbiter.version>0.9.1</arbiter.version>
    <rl4j.version>0.9.1</rl4j.version>

    <!-- For Spark examples: change the _1 to _2 to switch between Spark 1 and Spark 2 -->
    <dl4j.spark.version>0.9.1_spark_2</dl4j.spark.version>
    <datavec.spark.version>0.9.1_spark_2</datavec.spark.version>

    <!-- Scala binary version: DL4J's Spark and UI functionality are released with both Scala 2.10 and 2.11 support -->
    <scala.binary.version>2.11</scala.binary.version>

    <guava.version>19.0</guava.version>
    <logback.version>1.1.7</logback.version>
    <jfreechart.version>1.0.13</jfreechart.version>
    <jcommon.version>1.0.23</jcommon.version>
    <maven-compiler-plugin.version>3.6.1</maven-compiler-plugin.version>
    <maven-shade-plugin.version>2.4.3</maven-shade-plugin.version>
    <exec-maven-plugin.version>1.4.0</exec-maven-plugin.version>
    <maven.minimum.version>3.3.1</maven.minimum.version>
    <javafx.version>2.2.3</javafx.version>
    <!--<javafx.runtime.lib.jar>${env.JAVAFX_HOME}/jfxrt.jar</javafx.runtime.lib.jar>-->
    <aws.sdk.version>1.11.109</aws.sdk.version>
    <jackson.version>2.6.6</jackson.version>
    <scala.plugin.version>3.2.2</scala.plugin.version>
    <jcommander.version>1.27</jcommander.version>
  </properties>
  <dependencies>
    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
      <version>3.8.1</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.deeplearning4j</groupId>
      <artifactId>deeplearning4j-zoo</artifactId>
      <version>${dl4j.version}</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>commons-cli</groupId>
      <artifactId>commons-cli</artifactId>
      <version>1.3.1</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-core</artifactId>
      <version>2.6.6</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>org.jfree</groupId>
      <artifactId>jfreechart</artifactId>
      <version>1.5.0</version>
      <scope>compile</scope>
    </dependency>

    <dependency>
      <groupId>org.jfree</groupId>
      <artifactId>jcommon</artifactId>
      <version>1.0.24</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>org.deeplearning4j</groupId>
      <artifactId>deeplearning4j-nlp</artifactId>
      <version>${dl4j.version}</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>org.deeplearning4j</groupId>
      <artifactId>arbiter-deeplearning4j</artifactId>
      <version>${arbiter.version}</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>org.deeplearning4j</groupId>
      <artifactId>arbiter-ui_${scala.binary.version}</artifactId>
      <version>${arbiter.version}</version>
      <scope>compile</scope>
      <exclusions>
        <exclusion>
          <groupId>com.fasterxml.jackson.core</groupId>
          <artifactId>jackson-core</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <artifactId>datavec-data-codec</artifactId>
      <groupId>org.datavec</groupId>
      <version>${datavec.version}</version>
      <scope>compile</scope>
    </dependency>
    <dependency>
      <groupId>org.nd4j</groupId>
      <artifactId>nd4j-kryo_2.11</artifactId>
      <version>${nd4j.version}</version>
      <scope>compile</scope>
    </dependency>

    <dependency>
      <groupId>org.nd4j</groupId>
      <artifactId>${nd4j.backend}</artifactId>
      <version>${nd4j.version}</version>
      <scope>compile</scope>
    </dependency>

    <dependency>
      <groupId>org.deeplearning4j</groupId>
      <artifactId>dl4j-spark_${scala.binary.version}</artifactId>
      <version>${dl4j.spark.version}</version>
      <scope>compile</scope>
      <exclusions>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-sql_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-mllib_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-core_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-launcher_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-network-common_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-network-shuffle_${scala.binary.version}</artifactId>
        </exclusion>
      </exclusions>
    </dependency>

    <dependency>
      <groupId>org.deeplearning4j</groupId>
      <artifactId>dl4j-spark-parameterserver_${scala.binary.version}</artifactId>
      <version>${dl4j.spark.version}</version>
      <scope>compile</scope>
      <exclusions>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-sql_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-mllib_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-core_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-launcher_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-network-common_${scala.binary.version}</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.spark</groupId>
          <artifactId>spark-network-shuffle_${scala.binary.version}</artifactId>
        </exclusion>
      </exclusions>
    </dependency>

    <dependency>
      <groupId>com.beust</groupId>
      <artifactId>jcommander</artifactId>
      <version>${jcommander.version}</version>
    </dependency>

    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>aws-java-sdk-emr</artifactId>
      <version>${aws.sdk.version}</version>
      <scope>compile</scope>
    </dependency>

    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>aws-java-sdk-s3</artifactId>
      <version>${aws.sdk.version}</version>
      <scope>compile</scope>
    </dependency>

    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.binary.version}</artifactId>
      <version>2.1.0</version>
      <scope>compile</scope>
    </dependency>
  </dependencies>
</project>
